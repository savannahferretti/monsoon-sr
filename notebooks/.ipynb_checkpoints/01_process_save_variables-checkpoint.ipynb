{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea55fc7-4547-4616-b7d1-f63270d7899b",
   "metadata": {},
   "source": [
    "# Download and Save Cloud Data\n",
    "\n",
    "This notebook downloads variables needed to calculate the precipitation-buoyancy POD from multiple cloud stores (thermodynamic variables from ERA5, and precipitation from IMERG V06)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556d96a-6654-4913-a525-af2ae8ca9cbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f38b2be-cb9b-4c5e-9472-e8ab73faa1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import fsspec\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import planetary_computer\n",
    "from datetime import datetime\n",
    "import pystac_client as pystac\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7e48d-6996-4a95-b182-aa23f6aa8b64",
   "metadata": {
    "tags": []
   },
   "source": [
    "## User-Defined Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d061ab1-c52c-4ea7-8aee-f4ffffc0042e",
   "metadata": {},
   "source": [
    "Define the user's name/email (for data download attribution), set the directory where the variable data will be saved, and specify subsetting parameters (i.e., years, months, and latitude/longitude/pressure level ranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871799ff-87fe-41d5-ba9d-93b6b9a5b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR    = 'Savannah L. Ferretti'\n",
    "EMAIL     = 'savannah.ferretti@uci.edu'\n",
    "SAVEDIR   = '/global/cfs/cdirs/m4334/sferrett/monsoon-pod/data/raw'\n",
    "YEARS     = [2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020]\n",
    "MONTHS    = [6,7,8]\n",
    "LATRANGE  = (5.,25.) \n",
    "LONRANGE  = (60.,90.)\n",
    "LEVRANGE  = (500.,1000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354bbaad-f4d0-46ec-8cb0-a6e0ac4717d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import ERA5, IMERG V06, and GPCP Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d2807-fe30-43d4-ba92-cc9f85b5b8ed",
   "metadata": {},
   "source": [
    "The raw data for this analysis is accessible through publicly available cloud stores. ERA5 data, at its native hourly frequency and 0.25° x 0.25° spatial resolution, can be found on the LEAP Pangeo Data Catalog [here](https://catalog.leap.columbia.edu/feedstock/arco-era5). IMERG V06 data, provided at half-hourly frequency at 0.1° x 0.1° spatial resolution, can be accessed via Microsoft Planetary Computer [here](https://planetarycomputer.microsoft.com/dataset/gpm-imerg). GPCP data, available at daily frequency with 1.0° x 1.0° spatial resolution, is also hosted on the LEAP Pangeo Data Catalog [here](https://catalog.leap.columbia.edu/feedstock/global-precipitation-climatology-project). To efficiently handle these large datasets, the following functions lazily load all data into Xarray.Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a460b85c-348e-4619-a98e-a546808f3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_era5():\n",
    "    store = 'gs://gcp-public-data-arco-era5/ar/1959-2022-full_37-1h-0p25deg-chunk-1.zarr-v2/'\n",
    "    ds    = xr.open_zarr(store,decode_times=True)  \n",
    "    return ds\n",
    "\n",
    "def get_imerg():\n",
    "    store   = 'https://planetarycomputer.microsoft.com/api/stac/v1'\n",
    "    catalog = pystac.Client.open(store,modifier=planetary_computer.sign_inplace)\n",
    "    assets  = catalog.get_collection('gpm-imerg-hhr').assets['zarr-abfs']\n",
    "    ds      = xr.open_zarr(fsspec.get_mapper(assets.href,**assets.extra_fields['xarray:storage_options']),consolidated=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adfcfd5-f524-4691-b06c-3e3dca74547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5  = get_era5()\n",
    "imerg = get_imerg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0deb8-eb3a-441f-b19b-742ed7a070f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Extract Necessary Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca7bab-0969-4ec2-83a1-9e35fa3d3eb2",
   "metadata": {},
   "source": [
    "We only need four variables from these three datasets: precipitation from IMERG V06 and GPCP, and surface pressure, specific humidity, and temperature from ERA5. Convert units as necessary, and remove unrealistic values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78640fca-74f8-40d1-a3da-b52f76970fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imergprdata  = imerg.precipitationCal.where(\n",
    "    (imerg.precipitationCal!=-9999.9)&\n",
    "    (imerg.precipitationCal>=0),\n",
    "    np.nan)*24 # mm/hr to mm/day\n",
    "gpcpprdata  = gpcp.precip.where(\n",
    "    (gpcp.precip!=-99999.)&\n",
    "    (gpcp.precip!=9.96921e+36)&\n",
    "    (gpcp.precip>=0),\n",
    "    np.nan)\n",
    "psdata = era5.surface_pressure/100 # Pa to hPa\n",
    "qdata  = era5.specific_humidity\n",
    "tdata  = era5.temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e39e91f-1e7d-442a-b1c3-8987f47aec8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c691b2-5e66-45d7-b689-a6343c30bb8c",
   "metadata": {},
   "source": [
    "The `preprocess()` function preprocesses each variable using the user-defined fields above. It standardizes dimensions, subsets the time and space dimensions, specifies pressure levels to keep (if applicable), and formats the metadata for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1437672-04ae-4916-aade-7e53433a2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(da):\n",
    "    dimnames = {'latitude':'lat','longitude':'lon','level':'lev'}\n",
    "    da = da.rename({oldname:newname for oldname,newname in dimnames.items() if oldname in da.dims})\n",
    "    targetdims = ['lev','time','lat','lon'] if 'lev' in da.dims else ['time','lat','lon']\n",
    "    extradims  = [dim for dim in da.dims if dim not in targetdims]\n",
    "    if extradims:\n",
    "        da = da.drop_dims(extradims)\n",
    "    for dim in targetdims:\n",
    "        if dim=='time':\n",
    "            if da.coords[dim].dtype.kind!='M':\n",
    "                da.coords[dim] = da.indexes[dim].to_datetimeindex()\n",
    "            da = da.sel(time=~da.time.to_index().duplicated(keep='first'))\n",
    "        elif dim=='lon':\n",
    "            da.coords[dim] = (da.coords[dim]+180)%360-180        \n",
    "        elif dim!='time':\n",
    "            da.coords[dim] = da.coords[dim].astype(float)\n",
    "    da = da.sortby(targetdims).transpose(*targetdims)   \n",
    "    return da\n",
    "    \n",
    "def subset(ds,years=YEARS,months=MONTHS,latrange=LATRANGE,lonrange=LONRANGE,levrange=LEVRANGE):\n",
    "    ds = ds.sel(time=(ds['time.year'].isin(years))&(ds['time.month'].isin(months)))\n",
    "    ds = ds.sel(lat=slice(*latrange),lon=slice(*lonrange))\n",
    "    if 'lev' in ds.dims:\n",
    "        ds = ds.sel(lev=slice(*levrange))\n",
    "    return ds\n",
    "    \n",
    "def preprocess(da,shortname,longname,units,years=YEARS,months=MONTHS,latrange=LATRANGE,lonrange=LONRANGE,levrange=LEVRANGE,author=AUTHOR,email=EMAIL):\n",
    "    da = standardize(da)\n",
    "    da = subset(da,years,months,latrange,lonrange,levrange)\n",
    "    ds = xr.Dataset(data_vars={shortname:([*da.dims],da.data)},\n",
    "                    coords={dim:da.coords[dim].data for dim in da.dims})\n",
    "    ds[shortname].attrs = dict(long_name=longname,units=units)\n",
    "    ds.time.attrs = dict(long_name='Time')\n",
    "    ds.lat.attrs  = dict(long_name='Latitude',units='°N')\n",
    "    ds.lon.attrs  = dict(long_name='Longitude',units='°E')\n",
    "    if 'lev' in ds.dims:\n",
    "        ds.lev.attrs = dict(long_name='Pressure level',units='hPa')\n",
    "    ds.attrs = dict(history=f'Created on {datetime.today().strftime(\"%Y-%m-%d\")} by {author} ({email})')\n",
    "    print(f'{longname}: {ds.nbytes*1e-9:.2f} GB')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580f3eea-928f-4884-905f-919e76ca2450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMERG V06 precipitation rate: 22.26 GB\n",
      "GPCP precipitation rate: 0.01 GB\n",
      "ERA5 surface pressure: 1.82 GB\n",
      "ERA5 specific humidity: 29.09 GB\n",
      "ERA5 air temperature: 29.09 GB\n"
     ]
    }
   ],
   "source": [
    "imergpr = preprocess(imergprdata,shortname='pr',longname='IMERG V06 precipitation rate',units='mm/day')\n",
    "gpcppr  = preprocess(gpcpprdata,shortname='pr',longname='GPCP precipitation rate',units='mm/day')\n",
    "ps = preprocess(psdata,shortname='ps',longname='ERA5 surface pressure',units='hPa')\n",
    "q  = preprocess(qdata,shortname='q',longname='ERA5 specific humidity',units='kg/kg')\n",
    "t  = preprocess(tdata,shortname='t',longname='ERA5 air temperature',units='K')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb9ec1-b257-40f4-a368-a28a15dd583a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7031bd7-f13d-405e-b88f-7a640ffa7235",
   "metadata": {},
   "source": [
    "Save each variable Xarray.Dataset as a netCDF file to `SAVEDIR`. The time it took to save the data to disk is commented on the right. A different machine or more efficient saving methods can alter this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca45f0d1-bb43-48e4-acb1-858f0300e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(ds,filename,savedir=SAVEDIR):\n",
    "    filepath = f'{savedir}/{filename}'\n",
    "    ds.to_netcdf(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589ca15d-3f9d-47a7-afdb-c7e82d520771",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(imergpr,'IMERG_precipitation_rate.nc') # 22m 53s\n",
    "save(gpcppr,'GPCP_precipitation_rate.nc')   # 6s\n",
    "save(ps,'ERA5_surface_pressure.nc')         # 5m 55s\n",
    "save(q,'ERA5_specific_humidity.nc')         # 4h 27m 1s\n",
    "save(t,'ERA5_temperature.nc')               # 2h 50m 42s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monsoon-pod",
   "language": "python",
   "name": "monsoon-pod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
