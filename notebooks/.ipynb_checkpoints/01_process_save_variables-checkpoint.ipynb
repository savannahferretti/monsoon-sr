{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea55fc7-4547-4616-b7d1-f63270d7899b",
   "metadata": {},
   "source": [
    "# Download and Save Cloud Data\n",
    "\n",
    "This notebook downloads raw variables needed for the analytical baselines, MLPs, and SR models from multiple cloud stores (thermodynamic variables from ERA5, and precipitation from IMERG V06)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556d96a-6654-4913-a525-af2ae8ca9cbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f38b2be-cb9b-4c5e-9472-e8ab73faa1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import fsspec\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import planetary_computer\n",
    "from datetime import datetime\n",
    "import pystac_client as pystac\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7e48d-6996-4a95-b182-aa23f6aa8b64",
   "metadata": {
    "tags": []
   },
   "source": [
    "## User-Defined Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d061ab1-c52c-4ea7-8aee-f4ffffc0042e",
   "metadata": {},
   "source": [
    "Define the user's name/email (for data download attribution), set the directory where the variable data will be saved, and specify subsetting parameters (i.e., years, months, and latitude/longitude/pressure level ranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871799ff-87fe-41d5-ba9d-93b6b9a5b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR    = 'Savannah L. Ferretti'\n",
    "EMAIL     = 'savannah.ferretti@uci.edu'\n",
    "SAVEDIR   = '/global/cfs/cdirs/m4334/sferrett/monsoon-sr/data/raw'\n",
    "YEARS     = [2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020]\n",
    "MONTHS    = [6,7,8]\n",
    "LATRANGE  = (5.,25.) \n",
    "LONRANGE  = (60.,90.)\n",
    "LEVRANGE  = (500.,1000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354bbaad-f4d0-46ec-8cb0-a6e0ac4717d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import ERA5 and IMERG V06 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d2807-fe30-43d4-ba92-cc9f85b5b8ed",
   "metadata": {},
   "source": [
    "The raw data for this analysis is accessible through publicly available cloud stores. ERA5 data, at its native hourly frequency and 0.25° x 0.25° spatial resolution, can be found on the LEAP Pangeo Data Catalog [here](https://catalog.leap.columbia.edu/feedstock/arco-era5). IMERG V06 data, provided at half-hourly frequency at 0.1° x 0.1° spatial resolution, can be accessed via Microsoft Planetary Computer [here](https://planetarycomputer.microsoft.com/dataset/gpm-imerg). To efficiently handle these large datasets, the following functions lazily load all data into Xarray.Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a460b85c-348e-4619-a98e-a546808f3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_era5():\n",
    "    store = 'gs://gcp-public-data-arco-era5/ar/1959-2022-full_37-1h-0p25deg-chunk-1.zarr-v2/'\n",
    "    ds    = xr.open_zarr(store,decode_times=True)  \n",
    "    return ds\n",
    "\n",
    "def get_imerg():\n",
    "    store   = 'https://planetarycomputer.microsoft.com/api/stac/v1'\n",
    "    catalog = pystac.Client.open(store,modifier=planetary_computer.sign_inplace)\n",
    "    assets  = catalog.get_collection('gpm-imerg-hhr').assets['zarr-abfs']\n",
    "    ds      = xr.open_zarr(fsspec.get_mapper(assets.href,**assets.extra_fields['xarray:storage_options']),consolidated=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adfcfd5-f524-4691-b06c-3e3dca74547e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/monsoon-pod/lib/python3.9/site-packages/fsspec/registry.py:249\u001b[0m, in \u001b[0;36mget_filesystem_class\u001b[0;34m(protocol)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 249\u001b[0m     register_implementation(protocol, \u001b[43m_import_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbit\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/monsoon-pod/lib/python3.9/site-packages/fsspec/registry.py:284\u001b[0m, in \u001b[0;36m_import_class\u001b[0;34m(fqp)\u001b[0m\n\u001b[1;32m    283\u001b[0m is_s3 \u001b[38;5;241m=\u001b[39m mod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3fs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 284\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_s3 \u001b[38;5;129;01mand\u001b[39;00m mod\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/monsoon-pod/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'adlfs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m era5  \u001b[38;5;241m=\u001b[39m get_era5()\n\u001b[0;32m----> 2\u001b[0m imerg \u001b[38;5;241m=\u001b[39m \u001b[43mget_imerg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mget_imerg\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m catalog \u001b[38;5;241m=\u001b[39m pystac\u001b[38;5;241m.\u001b[39mClient\u001b[38;5;241m.\u001b[39mopen(store,modifier\u001b[38;5;241m=\u001b[39mplanetary_computer\u001b[38;5;241m.\u001b[39msign_inplace)\n\u001b[1;32m      9\u001b[0m assets  \u001b[38;5;241m=\u001b[39m catalog\u001b[38;5;241m.\u001b[39mget_collection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpm-imerg-hhr\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39massets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzarr-abfs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m ds      \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_zarr(\u001b[43mfsspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43massets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhref\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43massets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_fields\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxarray:storage_options\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,consolidated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/.conda/envs/monsoon-pod/lib/python3.9/site-packages/fsspec/mapping.py:249\u001b[0m, in \u001b[0;36mget_mapper\u001b[0;34m(url, check, create, missing_exceptions, alternate_root, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create key-value interface for given URL and options\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03mThe URL will be of the form \"protocol://location\" and point to the root\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m``FSMap`` instance, the dict-like key-value store.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Removing protocol here - could defer to each open() on the backend\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m fs, urlpath \u001b[38;5;241m=\u001b[39m \u001b[43murl_to_fs\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m root \u001b[38;5;241m=\u001b[39m alternate_root \u001b[38;5;28;01mif\u001b[39;00m alternate_root \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m urlpath\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FSMap(root, fs, check, create, missing_exceptions\u001b[38;5;241m=\u001b[39mmissing_exceptions)\n",
      "File \u001b[0;32m~/.conda/envs/monsoon-pod/lib/python3.9/site-packages/fsspec/core.py:403\u001b[0m, in \u001b[0;36murl_to_fs\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m known_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    401\u001b[0m }\n\u001b[1;32m    402\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m known_kwargs}\n\u001b[0;32m--> 403\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43m_un_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m inkwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# Reverse iterate the chain, creating a nested target_* structure\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/monsoon-pod/lib/python3.9/site-packages/fsspec/core.py:351\u001b[0m, in \u001b[0;36m_un_chain\u001b[0;34m(path, kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(bits):\n\u001b[1;32m    350\u001b[0m     protocol \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotocol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m split_protocol(bit)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mget_filesystem_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m     extra_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_kwargs_from_urls(bit)\n\u001b[1;32m    353\u001b[0m     kws \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(protocol, {})\n",
      "File \u001b[0;32m~/.conda/envs/monsoon-pod/lib/python3.9/site-packages/fsspec/registry.py:251\u001b[0m, in \u001b[0;36mget_filesystem_class\u001b[0;34m(protocol)\u001b[0m\n\u001b[1;32m    249\u001b[0m         register_implementation(protocol, _import_class(bit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(bit\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merr\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m registry[protocol]\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotocol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mImportError\u001b[0m: Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage"
     ]
    }
   ],
   "source": [
    "era5  = get_era5()\n",
    "imerg = get_imerg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0deb8-eb3a-441f-b19b-742ed7a070f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract Necessary Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca7bab-0969-4ec2-83a1-9e35fa3d3eb2",
   "metadata": {},
   "source": [
    "We only need four variables from these three datasets: precipitation from IMERG V06 and GPCP, and surface pressure, specific humidity, and temperature from ERA5. Convert units as necessary, and remove unrealistic values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78640fca-74f8-40d1-a3da-b52f76970fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prdata = imerg.precipitationCal.where((imerg.precipitationCal!=-9999.9)&(imerg.precipitationCal>=0),np.nan)*24 # mm/hr to mm/day\n",
    "psdata = era5.surface_pressure/100 # Pa to hPa\n",
    "qdata  = era5.specific_humidity\n",
    "tdata  = era5.temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e39e91f-1e7d-442a-b1c3-8987f47aec8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c691b2-5e66-45d7-b689-a6343c30bb8c",
   "metadata": {},
   "source": [
    "The `preprocess()` function preprocesses each variable using the user-defined fields above. It standardizes dimensions, subsets the time and space dimensions, specifies pressure levels to keep (if applicable), and formats the metadata for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1437672-04ae-4916-aade-7e53433a2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(da):\n",
    "    dimnames = {'latitude':'lat','longitude':'lon','level':'lev'}\n",
    "    da = da.rename({oldname:newname for oldname,newname in dimnames.items() if oldname in da.dims})\n",
    "    targetdims = ['lev','time','lat','lon'] if 'lev' in da.dims else ['time','lat','lon']\n",
    "    extradims  = [dim for dim in da.dims if dim not in targetdims]\n",
    "    if extradims:\n",
    "        da = da.drop_dims(extradims)\n",
    "    for dim in targetdims:\n",
    "        if dim=='time':\n",
    "            if da.coords[dim].dtype.kind!='M':\n",
    "                da.coords[dim] = da.indexes[dim].to_datetimeindex()\n",
    "            da = da.sel(time=~da.time.to_index().duplicated(keep='first'))\n",
    "        elif dim=='lon':\n",
    "            da.coords[dim] = (da.coords[dim]+180)%360-180        \n",
    "        elif dim!='time':\n",
    "            da.coords[dim] = da.coords[dim].astype(float)\n",
    "    da = da.sortby(targetdims).transpose(*targetdims)   \n",
    "    return da\n",
    "    \n",
    "def subset(ds,years=YEARS,months=MONTHS,latrange=LATRANGE,lonrange=LONRANGE,levrange=LEVRANGE):\n",
    "    ds = ds.sel(time=(ds['time.year'].isin(years))&(ds['time.month'].isin(months)))\n",
    "    ds = ds.sel(lat=slice(*latrange),lon=slice(*lonrange))\n",
    "    if 'lev' in ds.dims:\n",
    "        ds = ds.sel(lev=slice(*levrange))\n",
    "    return ds\n",
    "    \n",
    "def preprocess(da,shortname,longname,units,years=YEARS,months=MONTHS,latrange=LATRANGE,lonrange=LONRANGE,levrange=LEVRANGE,author=AUTHOR,email=EMAIL):\n",
    "    da = standardize(da)\n",
    "    da = subset(da,years,months,latrange,lonrange,levrange)\n",
    "    ds = xr.Dataset(data_vars={shortname:([*da.dims],da.data)},\n",
    "                    coords={dim:da.coords[dim].data for dim in da.dims})\n",
    "    ds[shortname].attrs = dict(long_name=longname,units=units)\n",
    "    ds.time.attrs = dict(long_name='Time')\n",
    "    ds.lat.attrs  = dict(long_name='Latitude',units='°N')\n",
    "    ds.lon.attrs  = dict(long_name='Longitude',units='°E')\n",
    "    if 'lev' in ds.dims:\n",
    "        ds.lev.attrs = dict(long_name='Pressure level',units='hPa')\n",
    "    ds.attrs = dict(history=f'Created on {datetime.today().strftime(\"%Y-%m-%d\")} by {author} ({email})')\n",
    "    print(f'{longname}: {ds.nbytes*1e-9:.2f} GB')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f3eea-928f-4884-905f-919e76ca2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = preprocess(prdata,shortname='pr',longname='IMERG V06 precipitation rate',units='mm/day')\n",
    "ps = preprocess(psdata,shortname='ps',longname='ERA5 surface pressure',units='hPa')\n",
    "q  = preprocess(qdata,shortname='q',longname='ERA5 specific humidity',units='kg/kg')\n",
    "t  = preprocess(tdata,shortname='t',longname='ERA5 air temperature',units='K')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb9ec1-b257-40f4-a368-a28a15dd583a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7031bd7-f13d-405e-b88f-7a640ffa7235",
   "metadata": {},
   "source": [
    "Save each variable Xarray.Dataset as a netCDF file to `SAVEDIR`. The time it took to save the data to disk is commented on the right. A different machine or more efficient saving methods can alter this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca45f0d1-bb43-48e4-acb1-858f0300e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(ds,filename,savedir=SAVEDIR):\n",
    "    filepath = f'{savedir}/{filename}'\n",
    "    ds.to_netcdf(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589ca15d-3f9d-47a7-afdb-c7e82d520771",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(pr,'IMERG_precipitation_rate.nc') # 22m 53s\n",
    "save(ps,'ERA5_surface_pressure.nc')    # 5m 55s\n",
    "save(q,'ERA5_specific_humidity.nc')    # 4h 27m 1s\n",
    "save(t,'ERA5_temperature.nc')          # 2h 50m 42s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monsoon-pod",
   "language": "python",
   "name": "monsoon-pod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
