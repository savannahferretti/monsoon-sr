{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c7b0c4-cff7-4fef-be0a-3c2a3da5d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Analysis and plotting notebook\n",
    "Load trained models and create visualizations\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import proplot as pplt\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from model_classes import BASELINE, MLP, MLPMODEL\n",
    "\n",
    "pplt.rc['figure.dpi'] = 100\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def inverse_log_normalize(normdata, c=1.0):\n",
    "    \"\"\"Inverse of log normalization\"\"\"\n",
    "    return np.exp(normdata) - c\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load the prepared data splits\"\"\"\n",
    "    with open('data/data_splits.pkl', 'rb') as f:\n",
    "        data_splits = pickle.load(f)\n",
    "    return data_splits\n",
    "\n",
    "def load_results():\n",
    "    \"\"\"Load training results\"\"\"\n",
    "    with open('results/baseline_results.pkl', 'rb') as f:\n",
    "        baselineresults = pickle.load(f)\n",
    "    \n",
    "    with open('results/mlp_results.pkl', 'rb') as f:\n",
    "        mlpresults = pickle.load(f)\n",
    "    \n",
    "    return baselineresults, mlpresults\n",
    "\n",
    "# Load data and results\n",
    "data_splits = load_data()\n",
    "baselineresults, mlpresults = load_results()\n",
    "\n",
    "# Extract test data\n",
    "xtest = data_splits['xtest']\n",
    "ytest = data_splits['ytest']\n",
    "\n",
    "# Plot training losses\n",
    "fig, axs = pplt.subplots(nrows=1, ncols=2, refwidth=4, refheight=2, sharex=True, sharey=False)\n",
    "axs.format(xlabel='Epoch', xlim=(0, 35))\n",
    "axs[0].format(title='MSE Loss Comparison', ylabel='MSE (mm/day)$^2$', ylim=(260, 350), yticks=10, yminorticks='none')\n",
    "axs[1].format(title='MAE Loss Comparison', ylabel='MAE (mm/day)', ylim=(4.7, 5.4))\n",
    "\n",
    "colors = ['blue5', 'blue9', 'red6', 'red9']\n",
    "\n",
    "# Organize models by activation and log transform status\n",
    "model_groups = {\n",
    "    'linear_regular': [],\n",
    "    'linear_log': [],\n",
    "    'relu_regular': [],\n",
    "    'relu_log': []\n",
    "}\n",
    "\n",
    "# Categorize models based on their properties\n",
    "for modelname, result in mlpresults.items():\n",
    "    if 'linear' in modelname.lower():\n",
    "        activation = 'linear'\n",
    "    elif 'relu' in modelname.lower():\n",
    "        activation = 'relu'\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    if result.get('logtransform', False):\n",
    "        model_groups[f'{activation}_log'].append(modelname)\n",
    "    else:\n",
    "        model_groups[f'{activation}_regular'].append(modelname)\n",
    "\n",
    "# Plot the results\n",
    "for i, (ax, loss_type) in enumerate(zip(axs, ['mse', 'mae'])):\n",
    "    # Find models with the right loss type\n",
    "    linear_regular = [m for m in model_groups['linear_regular'] if loss_type in m]\n",
    "    relu_regular = [m for m in model_groups['relu_regular'] if loss_type in m]\n",
    "    linear_log = [m for m in model_groups['linear_log'] if loss_type in m]\n",
    "    relu_log = [m for m in model_groups['relu_log'] if loss_type in m]\n",
    "    \n",
    "    if linear_regular:\n",
    "        modelname = linear_regular[0]\n",
    "        ax.plot(mlpresults[modelname]['trainlosses'], color=colors[0], linestyle='--', \n",
    "                label='Linear Training' if i == 0 else None)\n",
    "        ax.plot(mlpresults[modelname]['validlosses'], color=colors[0], linestyle='-', \n",
    "                label='Linear Validation' if i == 0 else None)\n",
    "    \n",
    "    if relu_regular:\n",
    "        modelname = relu_regular[0]\n",
    "        ax.plot(mlpresults[modelname]['trainlosses'], color=colors[1], linestyle='--', \n",
    "                label='Nonlinear Training' if i == 0 else None)\n",
    "        ax.plot(mlpresults[modelname]['validlosses'], color=colors[1], linestyle='-', \n",
    "                label='Nonlinear Validation' if i == 0 else None)\n",
    "    \n",
    "    if linear_log:\n",
    "        modelname = linear_log[0]\n",
    "        ax.plot(mlpresults[modelname]['trainlosses'], color=colors[2], linestyle='--', \n",
    "                label='Linear Training (Log-Normalized)' if i == 0 else None)\n",
    "        ax.plot(mlpresults[modelname]['validlosses'], color=colors[2], linestyle='-', \n",
    "                label='Linear Validation (Log-Normalized)' if i == 0 else None)\n",
    "    \n",
    "    if relu_log:\n",
    "        modelname = relu_log[0]\n",
    "        ax.plot(mlpresults[modelname]['trainlosses'], color=colors[3], linestyle='--', \n",
    "                label='Nonlinear Training (Log-Normalized)' if i == 0 else None)\n",
    "        ax.plot(mlpresults[modelname]['validlosses'], color=colors[3], linestyle='-', \n",
    "                label='Nonlinear Validation (Log-Normalized)' if i == 0 else None)\n",
    "\n",
    "fig.legend(loc='b', ncols=2)\n",
    "pplt.show()\n",
    "\n",
    "# Preprocess all data for plotting\n",
    "processed_data = {}\n",
    "ytrue_raw = ytest['pr'].values.flatten()\n",
    "\n",
    "for modelname, result in mlpresults.items():\n",
    "    if result.get('logtransform', False):\n",
    "        ypred_raw = inverse_log_normalize(result['testoutputs'], c=1.0).flatten()\n",
    "    else:\n",
    "        ypred_raw = result['testoutputs'].flatten()\n",
    "    \n",
    "    mask = (ytrue_raw > 0) & (ypred_raw > 0) & ~np.isnan(ytrue_raw) & ~np.isnan(ypred_raw)\n",
    "    \n",
    "    processed_data[modelname] = {\n",
    "        'ytrue': ytrue_raw[mask],\n",
    "        'ypred': ypred_raw[mask],\n",
    "        'description': result['description']\n",
    "    }\n",
    "\n",
    "for modelname, result in baselineresults.items():\n",
    "    ypred_raw = result['testoutputs'].flatten()\n",
    "    mask = (ytrue_raw > 0) & (ypred_raw > 0) & ~np.isnan(ytrue_raw) & ~np.isnan(ypred_raw)\n",
    "    \n",
    "    processed_data[modelname] = {\n",
    "        'ytrue': ytrue_raw[mask],\n",
    "        'ypred': ypred_raw[mask],\n",
    "        'description': result['description']\n",
    "    }\n",
    "\n",
    "# Calculate global limits\n",
    "all_ytrue = np.concatenate([data['ytrue'] for data in processed_data.values()])\n",
    "all_ypred = np.concatenate([data['ypred'] for data in processed_data.values()])\n",
    "globalmin = min(all_ytrue.min(), all_ypred.min())\n",
    "globalmax = max(all_ytrue.max(), all_ypred.max())\n",
    "globalmin = globalmin / (10**(0.1*(np.log10(globalmax) - np.log10(globalmin))))\n",
    "globalmax = globalmax * (10**(0.1*(np.log10(globalmax) - np.log10(globalmin))))\n",
    "\n",
    "# Plot actual vs predicted\n",
    "totalmodels = len(processed_data)\n",
    "ncols = 4\n",
    "nrows = (totalmodels + ncols - 1) // ncols\n",
    "\n",
    "fig, axs = pplt.subplots(nrows=nrows, ncols=ncols, refwidth=2, share=True)\n",
    "axs.format(xlabel='True Precipitation (mm/day)', xscale='log', xformatter='log', xlim=[globalmin, globalmax],\n",
    "           ylabel='Predicted Precipitation (mm/day)', yscale='log', yformatter='log', ylim=[globalmin, globalmax])\n",
    "\n",
    "bins = 100\n",
    "xedges = np.logspace(np.log10(globalmin), np.log10(globalmax), bins + 1)\n",
    "yedges = np.logspace(np.log10(globalmin), np.log10(globalmax), bins + 1)\n",
    "\n",
    "for plotidx, (modelname, data) in enumerate(processed_data.items()):\n",
    "    row = plotidx // ncols\n",
    "    col = plotidx % ncols\n",
    "    \n",
    "    ytrue = data['ytrue']\n",
    "    ypred = data['ypred']\n",
    "    \n",
    "    minlen = min(len(ytrue), len(ypred))\n",
    "    ytrue = ytrue[:minlen]\n",
    "    ypred = ypred[:minlen]\n",
    "    \n",
    "    hist, _, _ = np.histogram2d(ytrue, ypred, bins=(xedges, yedges))\n",
    "    hist = np.ma.masked_where(hist == 0, hist)\n",
    "    \n",
    "    mesh = axs[row, col].pcolormesh(xedges, yedges, hist.T, cmap='ColdHot', norm='log', levels=100)\n",
    "    axs[row, col].plot([globalmin, globalmax], [globalmin, globalmax], color='k', linestyle='--')\n",
    "    axs[row, col].format(title=data['description'])\n",
    "    \n",
    "    r2 = r2_score(ytrue, ypred)\n",
    "    axs[row, col].text(0.05, 0.90, f'R$^2$ = {r2:.3f}', transform=axs[row, col].transAxes)\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(processed_data), nrows * ncols):\n",
    "    row = i // ncols\n",
    "    col = i % ncols\n",
    "    axs[row, col].axis('off')\n",
    "\n",
    "fig.colorbar(mesh, loc='r', label='Counts', ticks=[0.1, 1, 10, 100, 1000, 10000, 100000])\n",
    "pplt.show()\n",
    "\n",
    "# Calculate metrics for all models\n",
    "allmetrics = {}\n",
    "for modelname, data in processed_data.items():\n",
    "    allmetrics[modelname] = {\n",
    "        'MSE': mean_squared_error(data['ytrue'], data['ypred']),\n",
    "        'RMSE': np.sqrt(mean_squared_error(data['ytrue'], data['ypred'])),\n",
    "        'MAE': mean_absolute_error(data['ytrue'], data['ypred']),\n",
    "        'R2': r2_score(data['ytrue'], data['ypred']),\n",
    "        'Title': data['description']\n",
    "    }\n",
    "\n",
    "metricsdf = pd.DataFrame.from_dict(allmetrics, orient='index')\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(metricsdf.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monsoon-sr",
   "language": "python",
   "name": "monsoon-sr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
